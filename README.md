# Home Retail ETL

## Описание проекта

Проект реализует простой ETL‑конвейер для имитации работы розничной сети:

1. **Генерация данных продаж** в виде CSV‑файлов (чеки с товарами).
2. **Автоматическая загрузка данных в PostgreSQL**.
3. **Автоматизация по расписанию** (cron на Linux или Планировщик задач Windows).

Проект предназначен для демонстрации навыков:

* работы с Python;
* генерации тестовых данных;
* загрузки данных в БД;
* проектирования таблиц и ограничений в PostgreSQL;
* настройки автоматизации и логирования.

---

## Структура репозитория

Структура проекта может **незначительно отличаться в зависимости от окружения** (локальная машина или сервер), так как часть каталогов создаётся автоматически при выполнении ETL-скриптов.

**Базовая логическая структура проекта:**

```
home-retail-etl/
├── data/                 # CSV-файлы с данными продаж
│   ├── processed/        # Уже обработанные файлы
│   └── *.csv             # Пример сгенерированной выгрузки
├── img/                  # Скриншоты проверки БД и автоматизации
├── logs/                 # Логи генерации и загрузки
├── sql/                  # SQL-скрипты (DDL)
│   └── create_tables.sql
├── src/                  # Исходный код
│   ├── generate_csv.py   # Генерация CSV
│   └── load_csv_to_db.py # Загрузка CSV в БД
├── .env                  # Переменные окружения (не коммитятся)
├── requirements.txt      # Зависимости Python
├── README.md             # Инструкция по проекту
└── venv/                 # Виртуальное окружение Python
```

---

## Используемые технологии

* Python 3.12
* PostgreSQL
* pandas
* psycopg2
* python-dotenv
* cron (Linux) / Task Scheduler (Windows)

---

## Структура базы данных

### Таблица `sales`

Таблица хранит строки чеков розничных продаж.
Одна строка = один товар в чеке.

**Поля:**

* `id` — bigint, primary key
* `doc_id` — идентификатор чека
* `item` — наименование товара
* `category` — категория товара
* `amount` — количество
* `price` — цена
* `discount` — скидка
* `shop_num` — номер магазина
* `cash_num` — номер кассы
* `file_name` — имя CSV‑файла источника
* `load_dttm` — дата и время загрузки строки

**Индексы и ограничения:**

* PK по `id`
* индекс по `doc_id`
* индекс по `(shop_num, cash_num)`
* CHECK:

  * `amount > 0`
  * `price >= 0`
  * `discount >= 0`

DDL‑скрипт создания таблицы находится в папке `sql/`.

---

## Подготовка окружения

### 1. Клонировать репозиторий

```bash
git clone https://github.com/mkudim/home-retail-etl
cd home-retail-etl
```

### 2. Создать виртуальное окружение и установить зависимости

```bash
python -m venv venv
source venv/bin/activate
pip install -r requirements.txt
```

### 3. Настроить переменные окружения

Создать файл `.env` в корне проекта:

```
DB_HOST=localhost
DB_PORT=5432
DB_NAME=retail_db
DB_USER=retail_user
DB_PASSWORD=your_password
```

---

## Создание таблиц в БД

Перед первой загрузкой необходимо создать таблицы:

```bash
psql -h localhost -U retail_user -d retail_db -f sql/create_tables.sql
```

---

## Запуск проекта вручную

### 1. Генерация CSV

```bash
./venv/bin/python src/generate_csv.py \
  --n-shops 3 \
  --min-cash 1 \
  --max-cash 3 \
  --min-checks 20 \
  --max-checks 40
```

В результате в папке `data/` появятся CSV‑файлы с продажами.

### 2. Загрузка данных в БД

```bash
./venv/bin/python src/load_csv_to_db.py
```

После успешной загрузки:

* данные появляются в таблице `sales`;
* обработанные файлы перемещаются в `data/processed/`;
* информация о процессе записывается в `logs/load.log`.

---

## Проверка корректности загрузки

Примеры SQL‑запросов:

```sql
-- количество загруженных строк
select count(*) from sales;

-- просмотр данных
select * from sales limit 20;

-- проверка адекватности значений
select count(*) from sales where amount <= 0 or price < 0;
```

Скриншоты результатов проверки приведены в папке `img/`.

---

## Идемпотентность загрузки

Загрузка реализована идемпотентно на уровне файлов:

* после успешной обработки CSV‑файлы перемещаются в `data/processed`;
* при повторном запуске загрузчика уже обработанные файлы не загружаются повторно;
* повторный запуск скрипта без новых CSV не изменяет количество строк в БД.

---

## Различия окружений (локальная машина и сервер)

Проект разрабатывался и проверялся в двух окружениях:

* **Локальная машина (Windows)** — используется для разработки, тестового запуска генерации данных и демонстрации автоматизации через Планировщик задач Windows.
* **Сервер (Linux)** — используется для автоматического ежедневного запуска ETL-процесса по расписанию (`cron`) и загрузки данных в PostgreSQL.

Особенности:

* каталог `data/processed/` создаётся автоматически при первом запуске загрузки и присутствует только в окружении, где выполняется `load_csv_to_db.py`;
* файлы логов загрузки (`load.log`) формируются в серверном окружении, где настроен `cron`;
* структура репозитория в Git отражает **логическую архитектуру проекта**, а не точный снимок файловой системы конкретной машины.

---

## Автоматизация

### Linux (cron)

На сервере используется `cron`:

* 06:00 (Пн–Сб) — генерация CSV
* 06:15 (Пн–Сб) — загрузка данных в БД

Логи сохраняются в папке `logs/`.

### Windows

Для локального запуска используется Планировщик задач Windows.
Скриншоты настройки приведены в папке `img/`.

---

## Итог

Проект демонстрирует полный цикл ETL:

* генерацию данных;
* загрузку в реляционную БД;
* контроль качества данных;
* автоматизацию по расписанию.

Репозиторий готов для развёртывания на новой машине и проверки работы проекта.
